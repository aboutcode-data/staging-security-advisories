advisory_id: CVE-2024-12704
datasource_id: vulnrichment_importer_v2/CVE-2024-12704
datasource_url: https://github.com/cisagov/vulnrichment/blob/develop/2024/12xxx/CVE-2024-12704.json
aliases: []
summary: A vulnerability in the LangChainLLM class of the run-llama/llama_index repository,
  version v0.12.5, allows for a Denial of Service (DoS) attack. The stream_complete method executes
  the llm using a thread and retrieves the result via the get_response_gen method of the StreamingGeneratorCallbackHandler
  class. If the thread terminates abnormally before the _llm.predict is executed, there is no
  exception handling for this case, leading to an infinite loop in the get_response_gen function.
  This can be triggered by providing an input of an incorrect type, causing the thread to terminate
  and the process to continue running indefinitely.
impacted_packages: []
severities:
  - score: '7.5'
    scoring_system: cvssv3
    scoring_elements: CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H
    published_at: None
    url:
  - score: Track
    scoring_system: ssvc
    scoring_elements: SSVCv2/E:P/A:Y/T:P/P:M/B:A/M:M/D:T/2025-03-20T17:54:16Z/
    published_at: None
    url:
weaknesses:
  - CWE-835
references:
  - url: https://github.com/run-llama/llama_index/commit/d1ecfb77578d089cbe66728f18f635c09aa32a05
    reference_type:
    reference_id:
  - url: https://huntr.com/bounties/a0b638fd-21c6-4ba7-b381-6ab98472a02a
    reference_type:
    reference_id:
