advisory_id: CVE-2024-34359
datasource_id: vulnrichment_importer_v2/CVE-2024-34359
datasource_url: https://github.com/cisagov/vulnrichment/blob/develop/2024/34xxx/CVE-2024-34359.json
aliases: []
summary: llama-cpp-python is the Python bindings for llama.cpp. `llama-cpp-python` depends on
  class `Llama` in `llama.py` to load `.gguf` llama.cpp or Latency Machine Learning Models.
  The `__init__` constructor built in the `Llama` takes several parameters to configure the
  loading and running of the model. Other than `NUMA, LoRa settings`, `loading tokenizers,`
  and `hardware settings`, `__init__` also loads the `chat template` from targeted `.gguf` 's
  Metadata and furtherly parses it to `llama_chat_format.Jinja2ChatFormatter.to_chat_handler()`
  to construct the `self.chat_handler` for this model. Nevertheless, `Jinja2ChatFormatter` parse
  the `chat template` within the Metadate with sandbox-less `jinja2.Environment`, which is furthermore
  rendered in `__call__` to construct the `prompt` of interaction. This allows `jinja2` Server
  Side Template Injection which leads to remote code execution by a carefully constructed payload.
impacted_packages: []
severities:
  - score: '9.7'
    scoring_system: cvssv3.1
    scoring_elements: CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H
    published_at: None
    url:
  - score: Track*
    scoring_system: ssvc
    scoring_elements: SSVCv2/E:P/A:N/T:T/P:M/B:A/M:M/D:R/2024-05-15T19:35:24Z/
    published_at: None
    url:
weaknesses:
  - CWE-76
references:
  - url: https://github.com/abetlen/llama-cpp-python/commit/b454f40a9a1787b2b5659cd2cb00819d983185df
    reference_type:
    reference_id:
  - url: https://github.com/abetlen/llama-cpp-python/security/advisories/GHSA-56xg-wfcc-g829
    reference_type:
    reference_id:
