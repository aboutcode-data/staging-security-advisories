advisory_id: CVE-2024-32878
datasource_id: vulnrichment_importer_v2/CVE-2024-32878
datasource_url: https://github.com/cisagov/vulnrichment/blob/develop/2024/32xxx/CVE-2024-32878.json
aliases: []
summary: Llama.cpp is LLM inference in C/C++. There is a use of uninitialized heap variable
  vulnerability in gguf_init_from_file, the code will free this uninitialized variable later.
  In a simple POC, it will directly cause a crash. If the file is carefully constructed, it
  may be possible to control this uninitialized value and cause arbitrary address free problems.
  This may further lead to be exploited. Causes llama.cpp to crash (DoS) and may even lead to
  arbitrary code execution (RCE). This vulnerability has been patched in commit b2740.
impacted_packages: []
severities:
  - score: '7.1'
    scoring_system: cvssv3.1
    scoring_elements: CVSS:3.1/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:L
    published_at: None
    url:
  - score: Track*
    scoring_system: ssvc
    scoring_elements: SSVCv2/E:P/A:N/T:T/P:M/B:A/M:M/D:R/2024-04-29T15:15:10Z/
    published_at: None
    url:
weaknesses:
  - CWE-456
references:
  - url: https://github.com/ggerganov/llama.cpp/releases/tag/b2749
    reference_type:
    reference_id:
  - url: https://github.com/ggerganov/llama.cpp/security/advisories/GHSA-p5mv-gjc5-mwqv
    reference_type:
    reference_id:
