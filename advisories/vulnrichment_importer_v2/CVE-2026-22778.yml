advisory_id: CVE-2026-22778
datasource_id: vulnrichment_importer_v2/CVE-2026-22778
datasource_url: https://github.com/cisagov/vulnrichment/blob/develop/2026/22xxx/CVE-2026-22778.json
aliases: []
summary: vLLM is an inference and serving engine for large language models (LLMs). From 0.8.3
  to before 0.14.1, when an invalid image is sent to vLLM's multimodal endpoint, PIL throws
  an error. vLLM returns this error to the client, leaking a heap address. With this leak, we
  reduce ASLR from 4 billion guesses to ~8 guesses. This vulnerability can be chained a heap
  overflow with JPEG2000 decoder in OpenCV/FFmpeg to achieve remote code execution. This vulnerability
  is fixed in 0.14.1.
impacted_packages: []
severities:
  - score: '9.8'
    scoring_system: cvssv3.1
    scoring_elements: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H
    published_at: None
    url:
  - score: Track
    scoring_system: ssvc
    scoring_elements: SSVCv2/E:N/A:Y/T:T/P:M/B:A/M:M/D:T/2026-02-03T15:40:34Z/
    published_at: None
    url:
weaknesses:
  - CWE-532
references:
  - url: https://github.com/vllm-project/vllm/pull/31987
    reference_type:
    reference_id:
  - url: https://github.com/vllm-project/vllm/pull/32319
    reference_type:
    reference_id:
  - url: https://github.com/vllm-project/vllm/releases/tag/v0.14.1
    reference_type:
    reference_id:
  - url: https://github.com/vllm-project/vllm/security/advisories/GHSA-4r2x-xpjr-7cvv
    reference_type:
    reference_id:
