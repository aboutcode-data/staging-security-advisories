advisory_id: CVE-2026-22807
datasource_id: vulnrichment_importer_v2/CVE-2026-22807
datasource_url: https://github.com/cisagov/vulnrichment/blob/develop/2026/22xxx/CVE-2026-22807.json
aliases: []
summary: vLLM is an inference and serving engine for large language models (LLMs). Starting
  in version 0.10.1 and prior to version 0.14.0, vLLM loads Hugging Face `auto_map` dynamic
  modules during model resolution without gating on `trust_remote_code`, allowing attacker-controlled
  Python code in a model repo/path to execute at server startup. An attacker who can influence
  the model repo/path (local directory or remote Hugging Face repo) can achieve arbitrary code
  execution on the vLLM host during model load. This happens before any request handling and
  does not require API access. Version 0.14.0 fixes the issue.
impacted_packages: []
severities:
  - score: '8.8'
    scoring_system: cvssv3.1
    scoring_elements: CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H
    published_at: None
    url:
  - score: Track
    scoring_system: ssvc
    scoring_elements: SSVCv2/E:N/A:N/T:T/P:M/B:A/M:M/D:T/2026-01-22T15:11:00Z/
    published_at: None
    url:
weaknesses:
  - CWE-94
references:
  - url: https://github.com/vllm-project/vllm/commit/78d13ea9de4b1ce5e4d8a5af9738fea71fb024e5
    reference_type:
    reference_id:
  - url: https://github.com/vllm-project/vllm/pull/32194
    reference_type:
    reference_id:
  - url: https://github.com/vllm-project/vllm/releases/tag/v0.14.0
    reference_type:
    reference_id:
  - url: https://github.com/vllm-project/vllm/security/advisories/GHSA-2pc9-4j83-qjmr
    reference_type:
    reference_id:
