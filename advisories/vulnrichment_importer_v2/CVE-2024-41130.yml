advisory_id: CVE-2024-41130
datasource_id: vulnrichment_importer_v2/CVE-2024-41130
datasource_url: https://github.com/cisagov/vulnrichment/blob/develop/2024/41xxx/CVE-2024-41130.json
aliases: []
summary: llama.cpp provides LLM inference in C/C++. Prior to b3427, llama.cpp contains a null
  pointer dereference in gguf_init_from_file. This vulnerability is fixed in b3427.
impacted_packages: []
severities:
  - score: '5.4'
    scoring_system: cvssv3.1
    scoring_elements: CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:L/A:L
    published_at: None
    url:
  - score: Track
    scoring_system: ssvc
    scoring_elements: SSVCv2/E:P/A:N/T:P/P:M/B:A/M:M/D:T/2024-07-22T17:50:21Z/
    published_at: None
    url:
weaknesses:
  - CWE-476
references:
  - url: https://github.com/ggerganov/llama.cpp/commit/07283b1a90e1320aae4762c7e03c879043910252
    reference_type:
    reference_id:
  - url: https://github.com/ggerganov/llama.cpp/security/advisories/GHSA-49q7-2jmh-92fp
    reference_type:
    reference_id:
