advisory_id: CVE-2023-29374
datasource_id: nvd_importer_v2/CVE-2023-29374
datasource_url: https://nvd.nist.gov/vuln/detail/CVE-2023-29374
aliases: []
summary: In LangChain through 0.0.131, the LLMMathChain chain allows prompt injection attacks
  that can execute arbitrary code via the Python exec method.
impacted_packages: []
severities:
  - score: '9.8'
    scoring_system: cvssv3.1
    scoring_elements: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H
    published_at: None
    url: https://nvd.nist.gov/vuln/detail/CVE-2023-29374
weaknesses:
  - CWE-74
references:
  - url: https://github.com/hwchase17/langchain/issues/1026
    reference_type:
    reference_id:
  - url: https://github.com/hwchase17/langchain/issues/814
    reference_type:
    reference_id:
  - url: https://github.com/hwchase17/langchain/pull/1119
    reference_type:
    reference_id:
  - url: https://twitter.com/rharang/status/1641899743608463365/photo/1
    reference_type:
    reference_id:
  - url: https://nvd.nist.gov/vuln/search/results?adv_search=true&isCpeNameSearch=true&query=cpe:2.3:a:langchain:langchain:*:*:*:*:*:*:*:*
    reference_type:
    reference_id: cpe:2.3:a:langchain:langchain:*:*:*:*:*:*:*:*
  - url: https://nvd.nist.gov/vuln/detail/CVE-2023-29374
    reference_type:
    reference_id: CVE-2023-29374
