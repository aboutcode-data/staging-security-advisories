advisory_id: GHSA-mcmc-2m55-j8jj
datasource_id: github_osv_importer_v2/GHSA-mcmc-2m55-j8jj
datasource_url: https://github.com/github/advisory-database/blob/main/advisories/github-reviewed/2026/01/GHSA-mcmc-2m55-j8jj/GHSA-mcmc-2m55-j8jj.json
aliases: []
summary: |
  vLLM introduced enhanced protection for CVE-2025-62164
  ### Summary
  The fix [here](https://github.com/vllm-project/vllm/pull/27204) for CVE-2025-62164 is not sufficient. The fix only disables prompt embeds by default rather than addressing the root cause, so the DoS vulnerability remains when the feature is enabled.

  ### Details
  vLLM's pending change attempts to fix the root cause, which is the missing sparse tensor validation.  PyTorch (~v2.0) disables sparse tensor validation (specifically, sparse tensor invariants checks) by default for performance reasons.  vLLM is adding the sparse tensor validation to ensure indices are valid, non-negative, and within bounds.  These checks help catch malformed tensors.

  ### PoC
  NA

  ### Impact
  Current fix only added a flag to disable/enable prompt embeds, so by default, prompt embeds feature is disabled in vLLM, which stops DoS attacks through the embeddings.  However, It doesnâ€™t address the problem when the flag is enabled and there is still potential for DoS attacks.

  ### Changes

  * https://github.com/vllm-project/vllm/pull/30649
impacted_packages:
  - purl: pkg:pypi/vllm
    affected_versions: vers:pypi/<0.11.1
    fixed_versions: vers:pypi/0.13.0
    fixed_in_commits: []
    introduced_in_commits: []
severities:
  - score: '8.8'
    scoring_system: cvssv3.1
    scoring_elements: CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H
    published_at: None
    url: https://github.com/github/advisory-database/blob/main/advisories/github-reviewed/2026/01/GHSA-mcmc-2m55-j8jj/GHSA-mcmc-2m55-j8jj.json
  - score: HIGH
    scoring_system: generic_textual
    scoring_elements:
    published_at: None
    url:
weaknesses:
  - CWE-787
  - CWE-20
  - CWE-502
  - CWE-123
references:
  - url: https://github.com/vllm-project/vllm
    reference_type:
    reference_id:
  - url: https://github.com/vllm-project/vllm/pull/30649
    reference_type:
    reference_id:
  - url: https://github.com/vllm-project/vllm/security/advisories/GHSA-mcmc-2m55-j8jj
    reference_type:
    reference_id:
