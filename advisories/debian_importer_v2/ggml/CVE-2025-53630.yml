advisory_id: ggml/CVE-2025-53630
datasource_id: debian_importer_v2/ggml/CVE-2025-53630
datasource_url: https://security-tracker.debian.org/tracker/CVE-2025-53630
aliases:
  - CVE-2025-53630
summary: llama.cpp is an inference of several LLM models in C/C++. Integer Overflow in the gguf_init_from_file_impl
  function in ggml/src/gguf.cpp can lead to Heap Out-of-Bounds Read/Write. This vulnerability
  is fixed in commit 26a48ad699d50b6268900062661bd22f3e792579.
impacted_packages:
  - purl: pkg:deb/debian/ggml?distro=sid
    affected_versions:
    fixed_versions: vers:deb/0.9.7-2
    fixed_in_commits: []
    introduced_in_commits: []
  - purl: pkg:deb/debian/ggml?distro=sid
    affected_versions:
    fixed_versions: vers:deb/0.0~git20250711.b6d2ebd-1
    fixed_in_commits: []
    introduced_in_commits: []
severities: []
weaknesses: []
references:
  - url: https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1109124
    reference_type:
    reference_id: 1109124
