advisory_id: llama.cpp/CVE-2025-52566
datasource_id: debian_importer_v2/llama.cpp/CVE-2025-52566
datasource_url: https://security-tracker.debian.org/tracker/CVE-2025-52566
aliases:
  - CVE-2025-52566
summary: llama.cpp is an inference of several LLM models in C/C++. Prior to version b5721, there
  is a signed vs. unsigned integer overflow in llama.cpp's tokenizer implementation (llama_vocab::tokenize)
  (src/llama-vocab.cpp:3036) resulting in unintended behavior in tokens copying size comparison.
  Allowing heap-overflowing llama.cpp inferencing engine with carefully manipulated text input
  during tokenization process. This issue has been patched in version b5721.
impacted_packages:
  - purl: pkg:deb/debian/llama.cpp?distro=sid
    affected_versions:
    fixed_versions: vers:deb/8064+dfsg-1
    fixed_in_commits: []
    introduced_in_commits: []
  - purl: pkg:deb/debian/llama.cpp?distro=sid
    affected_versions:
    fixed_versions: vers:deb/5760+dfsg-1
    fixed_in_commits: []
    introduced_in_commits: []
severities: []
weaknesses: []
references:
  - url: https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1108368
    reference_type:
    reference_id: 1108368
