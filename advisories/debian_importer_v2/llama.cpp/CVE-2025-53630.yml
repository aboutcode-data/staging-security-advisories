advisory_id: llama.cpp/CVE-2025-53630
datasource_id: debian_importer_v2/llama.cpp/CVE-2025-53630
datasource_url: https://security-tracker.debian.org/tracker/CVE-2025-53630
aliases:
  - CVE-2025-53630
summary: llama.cpp is an inference of several LLM models in C/C++. Integer Overflow in the gguf_init_from_file_impl
  function in ggml/src/gguf.cpp can lead to Heap Out-of-Bounds Read/Write. This vulnerability
  is fixed in commit 26a48ad699d50b6268900062661bd22f3e792579.
impacted_packages:
  - purl: pkg:deb/debian/llama.cpp?distro=sid
    affected_versions:
    fixed_versions: vers:deb/8064+dfsg-1
    fixed_in_commits: []
    introduced_in_commits: []
  - purl: pkg:deb/debian/llama.cpp?distro=sid
    affected_versions:
    fixed_versions: vers:deb/5882+dfsg-1
    fixed_in_commits: []
    introduced_in_commits: []
severities: []
weaknesses: []
references: []
