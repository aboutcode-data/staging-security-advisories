advisory_id: UBUNTU-CVE-2025-53630
datasource_id: ubuntu_osv_importer_v2/UBUNTU-CVE-2025-53630
datasource_url: https://github.com/canonical/ubuntu-security-notices/blob/main/osv/cve/2025/UBUNTU-CVE-2025-53630.json
aliases:
  - CVE-2025-53630
summary: llama.cpp is an inference of several LLM models in C/C++. Integer Overflow in the gguf_init_from_file_impl
  function in ggml/src/gguf.cpp can lead to Heap Out-of-Bounds Read/Write. This vulnerability
  is fixed in commit 26a48ad699d50b6268900062661bd22f3e792579.
impacted_packages:
  - purl: pkg:deb/ubuntu/llama.cpp?arch=source&distro=questing
    affected_versions: vers:deb/5318+dfsg-1|5318+dfsg-2|5713+dfsg-1|5760+dfsg-1|5760+dfsg-3|5760+dfsg-4|5882+dfsg-2
    fixed_versions:
    fixed_in_commits: []
    introduced_in_commits: []
severities:
  - score: '8.9'
    scoring_system: cvssv4
    scoring_elements: CVSS:4.0/AV:N/AC:L/AT:N/PR:N/UI:N/VC:H/VI:H/VA:H/SC:N/SI:N/SA:N/E:P
    published_at: None
    url: https://github.com/canonical/ubuntu-security-notices/blob/main/osv/cve/2025/UBUNTU-CVE-2025-53630.json
  - score: medium
    scoring_system: ubuntu-priority
    scoring_elements:
    published_at: None
    url: https://github.com/canonical/ubuntu-security-notices/blob/main/osv/cve/2025/UBUNTU-CVE-2025-53630.json
weaknesses: []
references:
  - url: https://github.com/ggml-org/llama.cpp/commit/26a48ad699d50b6268900062661bd22f3e792579
    reference_type:
    reference_id:
  - url: https://github.com/ggml-org/llama.cpp/security/advisories/GHSA-vgg9-87g3-85w8
    reference_type:
    reference_id:
  - url: https://ubuntu.com/security/CVE-2025-53630
    reference_type:
    reference_id:
  - url: https://www.cve.org/CVERecord?id=CVE-2025-53630
    reference_type:
    reference_id:
