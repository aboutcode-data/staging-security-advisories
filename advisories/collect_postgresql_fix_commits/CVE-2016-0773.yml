advisory_id: CVE-2016-0773
datasource_id: collect_postgresql_fix_commits/CVE-2016-0773
datasource_url: https://github.com/postgres/postgres
aliases: []
summary: |
  730c89b7926f55722bda94844bf53be7a42e9e7b:Last-minute updates for release notes.

  Security: CVE-2016-0773
  9dafc4130d948e9f0a1313e3708b79dee143c423:Last-minute updates for release notes.

  Security: CVE-2016-0773
  c846576a6d942f53a0881e0ae83bf5a31e69aa20:Last-minute updates for release notes.

  Security: CVE-2016-0773
  5e54757d41ad8b6e7fc2ab4961055c3872430cc4:Last-minute updates for release notes.

  Security: CVE-2016-0773
  129b6cf5ebc26f23d13371561bb9df643b3f6592:Last-minute updates for release notes.

  Security: CVE-2016-0773
  02292845ac6d6ec09d79abf1dbb0538e14582743:Last-minute updates for release notes.

  Security: CVE-2016-0773
  98d6b73059c31102892dc6cc4a340c2ba09b7fa6:Fix some regex issues with out-of-range characters and large char ranges.

  Previously, our regex code defined CHR_MAX as 0xfffffffe, which is a
  bad choice because it is outside the range of type "celt" (int32).
  Characters approaching that limit could lead to infinite loops in logic
  such as "for (c = a; c <= b; c++)" where c is of type celt but the
  range bounds are chr.  Such loops will work safely only if CHR_MAX+1
  is representable in celt, since c must advance to beyond b before the
  loop will exit.

  Fortunately, there seems no reason not to restrict CHR_MAX to 0x7ffffffe.
  It's highly unlikely that Unicode will ever assign codes that high, and
  none of our other backend encodings need characters beyond that either.

  In addition to modifying the macro, we have to explicitly enforce character
  range restrictions on the values of \u, \U, and \x escape sequences, else
  the limit is trivially bypassed.

  Also, the code for expanding case-independent character ranges in bracket
  expressions had a potential integer overflow in its calculation of the
  number of characters it could generate, which could lead to allocating too
  small a character vector and then overwriting memory.  An attacker with the
  ability to supply arbitrary regex patterns could easily cause transient DOS
  via server crashes, and the possibility for privilege escalation has not
  been ruled out.

  Quite aside from the integer-overflow problem, the range expansion code was
  unnecessarily inefficient in that it always produced a result consisting of
  individual characters, abandoning the knowledge that we had a range to
  start with.  If the input range is large, this requires excessive memory.
  Change it so that the original range is reported as-is, and then we add on
  any case-equivalent characters that are outside that range.  With this
  approach, we can bound the number of individual characters allowed without
  sacrificing much.  This patch allows at most 100000 individual characters,
  which I believe to be more than the number of case pairs existing in
  Unicode, so that the restriction will never be hit in practice.

  It's still possible for range() to take awhile given a large character code
  range, so also add statement-cancel detection to its loop.  The downstream
  function dovec() also lacked cancel detection, and could take a long time
  given a large output from range().

  Per fuzz testing by Greg Stark.  Back-patch to all supported branches.

  Security: CVE-2016-0773
  e93516cf7fa10ffaad1fa1f096d88fce21cc7c56:Fix some regex issues with out-of-range characters and large char ranges.

  Previously, our regex code defined CHR_MAX as 0xfffffffe, which is a
  bad choice because it is outside the range of type "celt" (int32).
  Characters approaching that limit could lead to infinite loops in logic
  such as "for (c = a; c <= b; c++)" where c is of type celt but the
  range bounds are chr.  Such loops will work safely only if CHR_MAX+1
  is representable in celt, since c must advance to beyond b before the
  loop will exit.

  Fortunately, there seems no reason not to restrict CHR_MAX to 0x7ffffffe.
  It's highly unlikely that Unicode will ever assign codes that high, and
  none of our other backend encodings need characters beyond that either.

  In addition to modifying the macro, we have to explicitly enforce character
  range restrictions on the values of \u, \U, and \x escape sequences, else
  the limit is trivially bypassed.

  Also, the code for expanding case-independent character ranges in bracket
  expressions had a potential integer overflow in its calculation of the
  number of characters it could generate, which could lead to allocating too
  small a character vector and then overwriting memory.  An attacker with the
  ability to supply arbitrary regex patterns could easily cause transient DOS
  via server crashes, and the possibility for privilege escalation has not
  been ruled out.

  Quite aside from the integer-overflow problem, the range expansion code was
  unnecessarily inefficient in that it always produced a result consisting of
  individual characters, abandoning the knowledge that we had a range to
  start with.  If the input range is large, this requires excessive memory.
  Change it so that the original range is reported as-is, and then we add on
  any case-equivalent characters that are outside that range.  With this
  approach, we can bound the number of individual characters allowed without
  sacrificing much.  This patch allows at most 100000 individual characters,
  which I believe to be more than the number of case pairs existing in
  Unicode, so that the restriction will never be hit in practice.

  It's still possible for range() to take awhile given a large character code
  range, so also add statement-cancel detection to its loop.  The downstream
  function dovec() also lacked cancel detection, and could take a long time
  given a large output from range().

  Per fuzz testing by Greg Stark.  Back-patch to all supported branches.

  Security: CVE-2016-0773
  6403a6b745d434d3b4275d74f11e1d3cd422119e:Fix some regex issues with out-of-range characters and large char ranges.

  Previously, our regex code defined CHR_MAX as 0xfffffffe, which is a
  bad choice because it is outside the range of type "celt" (int32).
  Characters approaching that limit could lead to infinite loops in logic
  such as "for (c = a; c <= b; c++)" where c is of type celt but the
  range bounds are chr.  Such loops will work safely only if CHR_MAX+1
  is representable in celt, since c must advance to beyond b before the
  loop will exit.

  Fortunately, there seems no reason not to restrict CHR_MAX to 0x7ffffffe.
  It's highly unlikely that Unicode will ever assign codes that high, and
  none of our other backend encodings need characters beyond that either.

  In addition to modifying the macro, we have to explicitly enforce character
  range restrictions on the values of \u, \U, and \x escape sequences, else
  the limit is trivially bypassed.

  Also, the code for expanding case-independent character ranges in bracket
  expressions had a potential integer overflow in its calculation of the
  number of characters it could generate, which could lead to allocating too
  small a character vector and then overwriting memory.  An attacker with the
  ability to supply arbitrary regex patterns could easily cause transient DOS
  via server crashes, and the possibility for privilege escalation has not
  been ruled out.

  Quite aside from the integer-overflow problem, the range expansion code was
  unnecessarily inefficient in that it always produced a result consisting of
  individual characters, abandoning the knowledge that we had a range to
  start with.  If the input range is large, this requires excessive memory.
  Change it so that the original range is reported as-is, and then we add on
  any case-equivalent characters that are outside that range.  With this
  approach, we can bound the number of individual characters allowed without
  sacrificing much.  This patch allows at most 100000 individual characters,
  which I believe to be more than the number of case pairs existing in
  Unicode, so that the restriction will never be hit in practice.

  It's still possible for range() to take awhile given a large character code
  range, so also add statement-cancel detection to its loop.  The downstream
  function dovec() also lacked cancel detection, and could take a long time
  given a large output from range().

  Per fuzz testing by Greg Stark.  Back-patch to all supported branches.

  Security: CVE-2016-0773
  fdc3139e2bd7d7c8b8e530e48b78bba48b72e9a1:Fix some regex issues with out-of-range characters and large char ranges.

  Previously, our regex code defined CHR_MAX as 0xfffffffe, which is a
  bad choice because it is outside the range of type "celt" (int32).
  Characters approaching that limit could lead to infinite loops in logic
  such as "for (c = a; c <= b; c++)" where c is of type celt but the
  range bounds are chr.  Such loops will work safely only if CHR_MAX+1
  is representable in celt, since c must advance to beyond b before the
  loop will exit.

  Fortunately, there seems no reason not to restrict CHR_MAX to 0x7ffffffe.
  It's highly unlikely that Unicode will ever assign codes that high, and
  none of our other backend encodings need characters beyond that either.

  In addition to modifying the macro, we have to explicitly enforce character
  range restrictions on the values of \u, \U, and \x escape sequences, else
  the limit is trivially bypassed.

  Also, the code for expanding case-independent character ranges in bracket
  expressions had a potential integer overflow in its calculation of the
  number of characters it could generate, which could lead to allocating too
  small a character vector and then overwriting memory.  An attacker with the
  ability to supply arbitrary regex patterns could easily cause transient DOS
  via server crashes, and the possibility for privilege escalation has not
  been ruled out.

  Quite aside from the integer-overflow problem, the range expansion code was
  unnecessarily inefficient in that it always produced a result consisting of
  individual characters, abandoning the knowledge that we had a range to
  start with.  If the input range is large, this requires excessive memory.
  Change it so that the original range is reported as-is, and then we add on
  any case-equivalent characters that are outside that range.  With this
  approach, we can bound the number of individual characters allowed without
  sacrificing much.  This patch allows at most 100000 individual characters,
  which I believe to be more than the number of case pairs existing in
  Unicode, so that the restriction will never be hit in practice.

  It's still possible for range() to take awhile given a large character code
  range, so also add statement-cancel detection to its loop.  The downstream
  function dovec() also lacked cancel detection, and could take a long time
  given a large output from range().

  Per fuzz testing by Greg Stark.  Back-patch to all supported branches.

  Security: CVE-2016-0773
  a61de2bc13354148fb0e3b2f5ef82fdbd41c51cc:Fix some regex issues with out-of-range characters and large char ranges.

  Previously, our regex code defined CHR_MAX as 0xfffffffe, which is a
  bad choice because it is outside the range of type "celt" (int32).
  Characters approaching that limit could lead to infinite loops in logic
  such as "for (c = a; c <= b; c++)" where c is of type celt but the
  range bounds are chr.  Such loops will work safely only if CHR_MAX+1
  is representable in celt, since c must advance to beyond b before the
  loop will exit.

  Fortunately, there seems no reason not to restrict CHR_MAX to 0x7ffffffe.
  It's highly unlikely that Unicode will ever assign codes that high, and
  none of our other backend encodings need characters beyond that either.

  In addition to modifying the macro, we have to explicitly enforce character
  range restrictions on the values of \u, \U, and \x escape sequences, else
  the limit is trivially bypassed.

  Also, the code for expanding case-independent character ranges in bracket
  expressions had a potential integer overflow in its calculation of the
  number of characters it could generate, which could lead to allocating too
  small a character vector and then overwriting memory.  An attacker with the
  ability to supply arbitrary regex patterns could easily cause transient DOS
  via server crashes, and the possibility for privilege escalation has not
  been ruled out.

  Quite aside from the integer-overflow problem, the range expansion code was
  unnecessarily inefficient in that it always produced a result consisting of
  individual characters, abandoning the knowledge that we had a range to
  start with.  If the input range is large, this requires excessive memory.
  Change it so that the original range is reported as-is, and then we add on
  any case-equivalent characters that are outside that range.  With this
  approach, we can bound the number of individual characters allowed without
  sacrificing much.  This patch allows at most 100000 individual characters,
  which I believe to be more than the number of case pairs existing in
  Unicode, so that the restriction will never be hit in practice.

  It's still possible for range() to take awhile given a large character code
  range, so also add statement-cancel detection to its loop.  The downstream
  function dovec() also lacked cancel detection, and could take a long time
  given a large output from range().

  Per fuzz testing by Greg Stark.  Back-patch to all supported branches.

  Security: CVE-2016-0773
  3bb3f42f3749d40b8d4de65871e8d828b18d4a45:Fix some regex issues with out-of-range characters and large char ranges.

  Previously, our regex code defined CHR_MAX as 0xfffffffe, which is a
  bad choice because it is outside the range of type "celt" (int32).
  Characters approaching that limit could lead to infinite loops in logic
  such as "for (c = a; c <= b; c++)" where c is of type celt but the
  range bounds are chr.  Such loops will work safely only if CHR_MAX+1
  is representable in celt, since c must advance to beyond b before the
  loop will exit.

  Fortunately, there seems no reason not to restrict CHR_MAX to 0x7ffffffe.
  It's highly unlikely that Unicode will ever assign codes that high, and
  none of our other backend encodings need characters beyond that either.

  In addition to modifying the macro, we have to explicitly enforce character
  range restrictions on the values of \u, \U, and \x escape sequences, else
  the limit is trivially bypassed.

  Also, the code for expanding case-independent character ranges in bracket
  expressions had a potential integer overflow in its calculation of the
  number of characters it could generate, which could lead to allocating too
  small a character vector and then overwriting memory.  An attacker with the
  ability to supply arbitrary regex patterns could easily cause transient DOS
  via server crashes, and the possibility for privilege escalation has not
  been ruled out.

  Quite aside from the integer-overflow problem, the range expansion code was
  unnecessarily inefficient in that it always produced a result consisting of
  individual characters, abandoning the knowledge that we had a range to
  start with.  If the input range is large, this requires excessive memory.
  Change it so that the original range is reported as-is, and then we add on
  any case-equivalent characters that are outside that range.  With this
  approach, we can bound the number of individual characters allowed without
  sacrificing much.  This patch allows at most 100000 individual characters,
  which I believe to be more than the number of case pairs existing in
  Unicode, so that the restriction will never be hit in practice.

  It's still possible for range() to take awhile given a large character code
  range, so also add statement-cancel detection to its loop.  The downstream
  function dovec() also lacked cancel detection, and could take a long time
  given a large output from range().

  Per fuzz testing by Greg Stark.  Back-patch to all supported branches.

  Security: CVE-2016-0773
impacted_packages:
  - purl: pkg:github/postgres/postgres
    affected_versions:
    fixed_versions:
    fixed_in_commits:
      - vcs_url: https://github.com/postgres/postgres
        commit: 6403a6b745d434d3b4275d74f11e1d3cd422119e
    introduced_in_commits: []
  - purl: pkg:github/postgres/postgres
    affected_versions:
    fixed_versions:
    fixed_in_commits:
      - vcs_url: https://github.com/postgres/postgres
        commit: 730c89b7926f55722bda94844bf53be7a42e9e7b
    introduced_in_commits: []
  - purl: pkg:github/postgres/postgres
    affected_versions:
    fixed_versions:
    fixed_in_commits:
      - vcs_url: https://github.com/postgres/postgres
        commit: 3bb3f42f3749d40b8d4de65871e8d828b18d4a45
    introduced_in_commits: []
  - purl: pkg:github/postgres/postgres
    affected_versions:
    fixed_versions:
    fixed_in_commits:
      - vcs_url: https://github.com/postgres/postgres
        commit: 02292845ac6d6ec09d79abf1dbb0538e14582743
    introduced_in_commits: []
  - purl: pkg:github/postgres/postgres
    affected_versions:
    fixed_versions:
    fixed_in_commits:
      - vcs_url: https://github.com/postgres/postgres
        commit: 9dafc4130d948e9f0a1313e3708b79dee143c423
    introduced_in_commits: []
  - purl: pkg:github/postgres/postgres
    affected_versions:
    fixed_versions:
    fixed_in_commits:
      - vcs_url: https://github.com/postgres/postgres
        commit: 129b6cf5ebc26f23d13371561bb9df643b3f6592
    introduced_in_commits: []
  - purl: pkg:github/postgres/postgres
    affected_versions:
    fixed_versions:
    fixed_in_commits:
      - vcs_url: https://github.com/postgres/postgres
        commit: fdc3139e2bd7d7c8b8e530e48b78bba48b72e9a1
    introduced_in_commits: []
  - purl: pkg:github/postgres/postgres
    affected_versions:
    fixed_versions:
    fixed_in_commits:
      - vcs_url: https://github.com/postgres/postgres
        commit: 5e54757d41ad8b6e7fc2ab4961055c3872430cc4
    introduced_in_commits: []
  - purl: pkg:github/postgres/postgres
    affected_versions:
    fixed_versions:
    fixed_in_commits:
      - vcs_url: https://github.com/postgres/postgres
        commit: c846576a6d942f53a0881e0ae83bf5a31e69aa20
    introduced_in_commits: []
  - purl: pkg:github/postgres/postgres
    affected_versions:
    fixed_versions:
    fixed_in_commits:
      - vcs_url: https://github.com/postgres/postgres
        commit: a61de2bc13354148fb0e3b2f5ef82fdbd41c51cc
    introduced_in_commits: []
  - purl: pkg:github/postgres/postgres
    affected_versions:
    fixed_versions:
    fixed_in_commits:
      - vcs_url: https://github.com/postgres/postgres
        commit: e93516cf7fa10ffaad1fa1f096d88fce21cc7c56
    introduced_in_commits: []
  - purl: pkg:github/postgres/postgres
    affected_versions:
    fixed_versions:
    fixed_in_commits:
      - vcs_url: https://github.com/postgres/postgres
        commit: 98d6b73059c31102892dc6cc4a340c2ba09b7fa6
    introduced_in_commits: []
severities: []
weaknesses: []
references:
  - url: https://github.com/postgres/postgres/tree/02292845ac6d6ec09d79abf1dbb0538e14582743
    reference_type: commit
    reference_id: 02292845ac6d6ec09d79abf1dbb0538e14582743
  - url: https://github.com/postgres/postgres/tree/129b6cf5ebc26f23d13371561bb9df643b3f6592
    reference_type: commit
    reference_id: 129b6cf5ebc26f23d13371561bb9df643b3f6592
  - url: https://github.com/postgres/postgres/tree/3bb3f42f3749d40b8d4de65871e8d828b18d4a45
    reference_type: commit
    reference_id: 3bb3f42f3749d40b8d4de65871e8d828b18d4a45
  - url: https://github.com/postgres/postgres/tree/5e54757d41ad8b6e7fc2ab4961055c3872430cc4
    reference_type: commit
    reference_id: 5e54757d41ad8b6e7fc2ab4961055c3872430cc4
  - url: https://github.com/postgres/postgres/tree/6403a6b745d434d3b4275d74f11e1d3cd422119e
    reference_type: commit
    reference_id: 6403a6b745d434d3b4275d74f11e1d3cd422119e
  - url: https://github.com/postgres/postgres/tree/730c89b7926f55722bda94844bf53be7a42e9e7b
    reference_type: commit
    reference_id: 730c89b7926f55722bda94844bf53be7a42e9e7b
  - url: https://github.com/postgres/postgres/tree/98d6b73059c31102892dc6cc4a340c2ba09b7fa6
    reference_type: commit
    reference_id: 98d6b73059c31102892dc6cc4a340c2ba09b7fa6
  - url: https://github.com/postgres/postgres/tree/9dafc4130d948e9f0a1313e3708b79dee143c423
    reference_type: commit
    reference_id: 9dafc4130d948e9f0a1313e3708b79dee143c423
  - url: https://github.com/postgres/postgres/tree/a61de2bc13354148fb0e3b2f5ef82fdbd41c51cc
    reference_type: commit
    reference_id: a61de2bc13354148fb0e3b2f5ef82fdbd41c51cc
  - url: https://github.com/postgres/postgres/tree/c846576a6d942f53a0881e0ae83bf5a31e69aa20
    reference_type: commit
    reference_id: c846576a6d942f53a0881e0ae83bf5a31e69aa20
  - url: https://github.com/postgres/postgres/tree/e93516cf7fa10ffaad1fa1f096d88fce21cc7c56
    reference_type: commit
    reference_id: e93516cf7fa10ffaad1fa1f096d88fce21cc7c56
  - url: https://github.com/postgres/postgres/tree/fdc3139e2bd7d7c8b8e530e48b78bba48b72e9a1
    reference_type: commit
    reference_id: fdc3139e2bd7d7c8b8e530e48b78bba48b72e9a1
