advisory_id: pypi/vllm/CVE-2024-8939
datasource_id: gitlab_importer_v2/pypi/vllm/CVE-2024-8939
datasource_url: https://gitlab.com/gitlab-org/advisories-community/-/blob/main/pypi/vllm/CVE-2024-8939.yml
aliases:
  - CVE-2024-8939
  - GHSA-wc36-9694-f9rf
summary: |
  vLLM Denial of Service via the best_of parameter
  A vulnerability was found in the ilab model serve component, where improper handling of the best_of parameter in the vllm JSON web API can lead to a Denial of Service (DoS). The API used for LLM-based sentence or chat completion accepts a best_of parameter to return the best completion from several options. When this parameter is set to a large value, the API does not handle timeouts or resource exhaustion properly, allowing an attacker to cause a DoS by consuming excessive system resources. This leads to the API becoming unresponsive, preventing legitimate users from accessing the service.
impacted_packages:
  - purl: pkg:pypi/vllm
    affected_versions: vers:pypi/<=0.5.0.post1
    fixed_versions: vers:pypi/
    fixed_in_commits: []
    introduced_in_commits: []
severities:
  - score:
    scoring_system: cvssv3.1
    scoring_elements: CVSS:3.1/AV:L/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H
    published_at: None
    url: https://gitlab.com/gitlab-org/advisories-community/-/blob/main/pypi/vllm/CVE-2024-8939.yml
weaknesses:
  - CWE-1035
  - CWE-937
  - CWE-400
references:
  - url: https://access.redhat.com/security/cve/CVE-2024-8939
    reference_type:
    reference_id:
  - url: https://bugzilla.redhat.com/show_bug.cgi?id=2312782
    reference_type:
    reference_id:
  - url: https://github.com/vllm-project/vllm
    reference_type:
    reference_id:
  - url: https://github.com/vllm-project/vllm/issues/6137
    reference_type:
    reference_id:
  - url: https://nvd.nist.gov/vuln/detail/CVE-2024-8939
    reference_type:
    reference_id: CVE-2024-8939
  - url: https://github.com/advisories/GHSA-wc36-9694-f9rf
    reference_type:
    reference_id: GHSA-wc36-9694-f9rf
